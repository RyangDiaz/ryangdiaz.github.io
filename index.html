<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ryan Diaz</title>
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    <nav>
        <ul>
            <li><a href="#news-section">News</a></li>
            <li><a href="#publications-section">Publications</a></li>
            <li><a href="#projects-section">Projects</a></li>
            <li><button id="theme-toggle">☀️</button></li>
        </ul>
    </nav>
    <div class="container">
        <header class="profile-header">
            <!-- Profile picture and biography -->
            <div class="profile-section">
                <div class="profile-pic-container">
                    <img src="assets/img/prof_pic.jpg" alt="Ryan Diaz" class="profile-pic">
                </div>
                <div class="bio">
                    <h1>Ryan Diaz</h1>
                    <p>Hello! I am an incoming first-year CS Ph.D. student at Rice University. My research interests include designing human-centric learning algorithms for robotic manipulation, and I will be doing research with <a href="https://unhelkar.github.io" target="_blank">Prof. Vaibhav Unhelkar</a> at the <a href="https://unhelkar.github.io/group/" target="_blank">Human-Centered AI and Robotics Group</a>. I'm always trying to explore new ways to help robots do cool things!</p>
                    <p>Previously, I was an undergraduate at the University of Minnesota where I worked with <a href="https://karthikdesingh.com" target="_blank">Prof. Karthik Desingh</a> at the <a href="https://rpm-lab.github.io" target="_blank">Robotics: Perception and Manipulation Lab</a> on multisensory contact-rich robotic manipulation. I also got the chance to do research on reinforcement learning for autonomous driving with <a href="https://engineering.wustl.edu/faculty/Yevgeniy-Vorobeychik.html" target="_blank">Prof. Yevgeniy Vorobeychik</a> at the <a href="https://sites.wustl.edu/csereu/" target="_blank">WashU CSE REU</a>.</p>
                    <p>Outside of academics and research, I enjoy cooking, reading, and worldbuilding (as well as procrastinating way too much on actually writing). Whether it be writing papers, writing code, or writing stories, the keyboard always calls...</p>
                    <p class="email-link-bio"><a href="mailto:rd88@rice.edu">rd88@rice.edu</a> / <a href="mailto:diazryan.g@gmail.com">diazryan.g@gmail.com</a> </p>
                    <div class="links-section">
                        <p>
                            <a href="assets/pdf/PhD_CV.pdf" target="_blank">CV</a> 
                            <a href="https://www.linkedin.com/in/ryan-diaz-a9b443251/" target="_blank">LinkedIn</a> 
                            <a href="https://github.com/RyangDiaz" target="_blank">GitHub</a> 
                            <a href="https://scholar.google.com/citations?user=pWyYktMAAAAJ" target="_blank">Google Scholar</a> 
                        </p>
                    </div>
                </div>
            </div>
        </header>

        <hr class="section-divider">

        <!-- News Section (Previously Updates) -->
        <section class="news-section" id="news-section">
            <h2>News</h2>
            <ul>
                <li><span class="update-date"><strong><em>[05/15/2025]</em></strong> </span> <span class="update-description">I graduated from UMN with a B.S. in Computer Science and Mathematics, summa cum laude with high distinction!</span></li>
                <li><span class="update-date"><strong><em>[05/01/2025]</em></strong> </span> <span class="update-description"><a href="https://rpm-lab-umn.github.io/auginsert/" target="_blank">AugInsert</a> was accepted to the <a href="https://sites.google.com/view/icra-2025-beyond-pick-place/home" target="_blank">Beyond Pick and Place Workshop</a> @ ICRA 2025!</span></li>
                <li><span class="update-date"><strong><em>[04/07/2025]</em></strong> </span> <span class="update-description">I will be starting a CS Ph.D. at Rice University in Fall 2025, advised by <a href="https://unhelkar.github.io" target="_blank">Prof. Vaibhav Unhelkar</a>!</span></li>
                <li><span class="update-date"><strong><em>[12/28/2024]</em></strong> </span> <span class="update-description">I was named an honorable mention for the <a href="https://cra.org/about/awards/outstanding-undergraduate-researcher-award/" target="_blank">2025 CRA Outstanding Undergraduate Researcher Award!</a></span></li>
                <li><span class="update-date"><strong><em>[10/22/2024]</em></strong> </span> <span class="update-description">Our project <a href="https://rpm-lab-umn.github.io/auginsert/" target="_blank">AugInsert</a> is now live on <a href="https://arxiv.org/abs/2410.14968" target="_blank">arXiv</a>! You can find an overview video of the project <a href="https://www.youtube.com/watch?v=UTA7sefgs2o" target="_blank">here</a>.</span></li>
                <li><span class="update-date"><strong><em>[04/26/2024]</em></strong> </span> <span class="update-description">This summer I am planning to go to the <a href="https://sites.wustl.edu/csereu/" target="_blank">CSE REU</a> at Washington University in St. Louis to work on algorithms for autonomous vehicle movement!</span></li>
                <li><span class="update-date"><strong><em>[01/30/2024]</em></strong> </span> <span class="update-description"><a href="https://arxiv.org/abs/2310.09943" target="_blank">Evaluating Robustness of Visual Representations</a> was accepted to <a href="https://www.ieee-icra.org/2024/" target="_blank">ICRA 2024</a>!</span></li>
                <li><span class="update-date"><strong><em>[12/10/2023]</em></strong> </span> <span class="update-description">Presented a video for the Fall 2023 Undergraduate Research Symposium at UMN! You can find an abstract of the project and the video <a href="https://ugresearch.umn.edu/presentation-opportunities/fall-symposium/presenters-2023/ryan-diaz" target="_blank">here</a>.</span></li>
                <li><span class="update-date"><strong><em>[10/23/2023]</em></strong> </span> <span class="update-description"><a href="https://arxiv.org/abs/2310.09943" target="_blank">Evaluating Robustness of Visual Representations</a> was accepted to the <a href="https://sites.google.com/view/corl2023-prl/home?authuser=0" target="_blank">2nd Pretraining for Robot Learning Workshop</a> @ CoRL 2023!</span></li>
                <li><span class="update-date"><strong><em>[04/25/2023]</em></strong> </span> <span class="update-description">Presented a poster at the Spring 2023 Undergraduate Research Symposium at UMN! You can find an abstract of the project <a href="https://ugresearch.umn.edu/presentation-opportunities/springsymposium/presenters-spring-2023/Ryan%20Diaz" target="_blank">here</a>.</span></li>
            </ul>
        </section>

        <hr class="section-divider">

        <!-- Publications Section -->
        <section class="publications-section" id="publications-section">
            <h2>Publications</h2>
            <div class="publication-entry">
                <div class="publication-image">
                    <img src="assets/img/publications/auginsert.gif" alt="auginsert gif">
                </div>
                <div class="publication-details">
                    <h3>AugInsert: Learning Robust Visual-Force Policies via Data Augmentation for Object Assembly Tasks</h3>
                    <p><strong>Ryan Diaz</strong>, Adam Imdieke, Vivek Veeriah, Karthik Desingh</p>
                    <p><em><strong>Beyond Pick and Place Workshop at ICRA 2025</strong></em></p>
                    <p>
                        <a href="https://arxiv.org/abs/2410.14968" target="_blank">[Paper]</a>/
                        <a href="https://rpm-lab-umn.github.io/auginsert/" target="_blank">[Website]</a>/
                        <a href="https://www.youtube.com/watch?v=UTA7sefgs2o" target="_blank">[Video]</a>/
                        <a href="https://github.com/RyangDiaz/auginsert" target="_blank">[Code]</a>
                    </p>
                    <p>We build a multisensory imitation learning framework and evaluate it on an extensive set of task variations for a peg-in-hole task. We also explore data augmentation as a possible technique for increasing a policy's robustness to these variations.</p>
                </div>
            </div>

            <div class="publication-entry">
                <div class="publication-image">
                    <img src="assets/img/publications/evaluating_robustness.gif" alt="evaluating robustness thumbnail">
                </div>
                <div class="publication-details">
                    <h3>Evaluating Robustness of Visual Representations for Object Assembly Task Requiring Spatio-Geometrical Reasoning</h3>
                    <p>Chahyon Ku, Carl Winge, <strong>Ryan Diaz</strong>, Wentao Yuan, Karthik Desingh</p>
                    <p><em><strong>IEEE International Conference on Robotics and Automation (ICRA) 2024</strong></br>
                    2nd Pretraining for Robot Learning Workshop at CoRL 2023</em></p>
                    <p>
                        <a href="https://arxiv.org/abs/2310.09943" target="_blank">[Paper]</a>/
                        <a href="https://sites.google.com/view/geometric-peg-in-hole" target="_blank">[Website]</a>/
                        <a href="https://www.youtube.com/watch?v=3e5QKCdmb7Q" target="_blank">[Video]</a>/
                        <a href="https://github.com/geometricpeginhole/geometric-peg-in-hole" target="_blank">[Code]</a>
                    </p>
                    <p>We introduce a novel dual-arm object assembly task that focuses on geometric and spatial reasoning. We compare multiple pretrained vision encoders in a behavior cloning framework across a large set of grasp and object geometry variations.</p>
                </div>
            </div>
        </section>

        <hr class="section-divider">

        <!-- Projects Section -->
        <section class="projects-section" id="projects-section">
            <h2>Projects</h2>
            <div class="project-entry publication-entry show"> <!-- Entry 1 -->
                <div class="project-image publication-image">
                    <img src="assets/img/projects/vtmae.png" alt="vtmae thumbnail">
                </div>
                <div class="project-details publication-details">
                    <h3>Multisensory Visuotactile Pretraining for Robotic Manipulation Tasks</h3>
                    <p><em>CSCI 5980: Deep Learning for Robot Manipulation (University of Minnesota)</em></p>
                    <p>
                        <a href="assets/pdf/CSCI5980_poster.pdf" target="_blank">[Poster]</a>/
                        <a href="https://drive.google.com/file/d/1dyahtcY6rpv9K3WFxizPoUE4RYLio7R2/view" target="_blank">[Video]</a>
                    </p>
                    <p>We implement a masked pretraining objective for a vision and force-torque observation encoder and perform downstream evaluation on a series of contact-rich robotic manipulation tasks.</p>
                </div>
            </div>

            <div class="project-entry publication-entry show"> <!-- Entry 2 -->
                <div class="project-image publication-image">
                    <img src="assets/img/projects/obstacle_avoidance.gif" alt="obstacle avoidance gif">
                </div>
                <div class="project-details publication-details">
                    <h3>Obstacle Detection and Avoidance in Simulated Autonomous Driving</h3>
                    <p><em>CSE REU (Washington University in St. Louis)</em></p>
                    <p>
                        <a href="assets/pdf/REU_report.pdf" target="_blank">[Report]</a>/
                        <a href="assets/pdf/REU_poster.pdf" target="_blank">[Poster]</a>/
                        <a href="https://github.com/RyangDiaz/carla-yolo-dataset-generator" target="_blank">[Detection Code]</a>/
                        <a href="https://github.com/RyangDiaz/carla-obstacle-avoidance" target="_blank">[RL Code]</a>
                    </p>
                    <p>We use an object detection module and reinforcement learning to build an obstacle avoidance pipeline for an autonomous vehicle in the CARLA simulation environment.</p>
                </div>
            </div>
            
            <div class="project-entry publication-entry show"> <!-- Entry 3 -->
                <div class="project-image publication-image">
                    <img src="assets/img/projects/fourier_features.gif" alt="fourier features gif">
                </div>
                <div class="project-details publication-details">
                    <h3>An Exploration of Fourier Features for Image and Video Representations</h3>
                    <p><em>MATH 5466: Mathematics of Machine Learning and Data Analysis II (University of Minnesota)</em></p>
                    <p>
                        <a href="assets/pdf/MATH5466_report.pdf" target="_blank">[Report]</a>/
                        <a href="https://github.com/RyangDiaz/fourier-features-video" target="_blank">[Code]</a>
                    </p>
                    <p>We investigate the effectiveness of Fourier Features in MLPs for coordinate-based representations of images and videos. We also explore their theoretical motivations via the Neural Tangent Kernel (NTK).</p>
                </div>
            </div>

            <button type="button" class="toggle-projects-btn" id="toggle-more-projects">More Projects ▼</button>

            <div class="project-entry publication-entry hide"> <!-- Entry 4 (Initially hidden) -->
                <div class="project-image publication-image">
                    <img src="assets/img/projects/news_political_bias.png" alt="political bias in news thumbnail">
                </div>
                <div class="project-details publication-details">
                    <h3>Temporal Political Bias Analysis in Media Using Language Models</h3>
                    <p><em>CSCI 5541: Natural Language Processing (University of Minnesota)</em></p>
                    <p>
                        <a href="assets/pdf/CSCI5541_report.pdf" target="_blank">[Report]</a>/
                        <a href="assets/pdf/CSCI5541_poster.pdf" target="_blank">[Poster]</a>/
                        <a href="https://github.com/RyangDiaz/temporal-political-bias-lm" target="_blank">[Code]</a>
                    </p>
                    <p>We use a pretrained language model to analyze the political bias of articles from various news sources over an extended period of time.</p>
                </div>
            </div>

            <div class="project-entry publication-entry hide"> <!-- Entry 5 (Initially hidden) -->
                <div class="project-image publication-image">
                    <img src="assets/img/projects/nerf_sam_seg.gif" alt="nerf sam seg gif">
                </div>
                <div class="project-details publication-details">
                    <h3>3D Semantic Segmentation of a Scene Using NeRFs and SAM</h3>
                    <p><em>CSCI 5561: Computer Vision (University of Minnesota)</em></p>
                    <p>
                        <a href="assets/pdf/CSCI5561_report.pdf" target="_blank">[Report]</a>
                    </p>
                    <p>We perform semantic segmentation of a 3D scene by applying a Segment Anything Model (SAM) to a NeRF-rendered scene from a series of 2D images.</p>
                </div>
            </div>

            <div class="project-entry publication-entry hide"> <!-- Entry 5 (Initially hidden) -->
                <div class="project-image publication-image">
                    <img src="assets/img/projects/slot_diffusion_policy.png" alt="slot diffusion policy gif">
                </div>
                <div class="project-details publication-details">
                    <h3>Object-Centric Representation for Imitation Learning in Robotics</h3>
                    <p><em>CSCI 5527: Deep Learning: Models, Computation, and Applications (University of Minnesota)</em></p>
                    <p>
                        <a href="assets/pdf/CSCI5527_report.pdf" target="_blank">[Report]</a>/
                        <a href="https://github.com/chahyon-ku/slot-diffusion-policy" target="_blank">[Code]</a>
                    </p>
                    <p>We explore the use of slot-based representations (via slot attention) in the diffusion policy framework for robotic manipulation tasks.</p>
                </div>
            </div>

            <div class="project-entry publication-entry hide"> <!-- Entry 5 (Initially hidden) -->
                <div class="project-image publication-image">
                    <img src="assets/img/projects/blender_obj_generation.png" alt="blender obj generation thumbnail">
                </div>
                <div class="project-details publication-details">
                    <h3>Programmatic Object Generation with Blender</h3>
                    <p><em>Undergraduate Research Scholarship Project (University of Minnesota)</em></p>
                    <p>
                        <a href="assets/pdf/URS_report.pdf" target="_blank">[Report]</a>/
                        <a href="assets/pdf/URS_poster.pdf" target="_blank">[Poster]</a>/
                        <a href="https://drive.google.com/file/d/11O7EzkdPCGOWmlAIpdVG5OkPKGhUArB_/view" target="_blank">[Video]</a>
                    </p>
                    <p>We utilize the Blender Python API to generate a large dataset of objects with wide varieties of geometries for use in simulating a peg-in-hole task.</p>
                </div>
            </div>

            <div class="project-entry publication-entry hide"> <!-- Entry 5 (Initially hidden) -->
                <div class="project-image publication-image">
                    <img src="assets/img/projects/freecell_ai.png" alt="freecell ai thumbnail">
                </div>
                <div class="project-details publication-details">
                    <h3>Using Search Algorithms to Solve Free-Cell Solitaire Games</h3>
                    <p><em>CSCI 4511W: Introduction to Artificial Intelligence (University of Minnesota)</em></p>
                    <p>
                        <a href="assets/pdf/CSCI4511W_report.pdf" target="_blank">[Report]</a>/
                        <a href="https://github.com/RyangDiaz/freecell-search-solver" target="_blank">[Code]</a>
                    </p>
                    <p>We compare both uninformed and informed search algorithms (using a wide variety of heuristics) for solving a scaled-down version of the free-cell solitaire game.</p>
                </div>
            </div>

            <div class="project-entry publication-entry hide"> <!-- Entry 5 (Initially hidden) -->
                <div class="project-image publication-image">
                    <img src="assets/img/projects/wrsct.gif" alt="wrsct gif">
                </div>
                <div class="project-details publication-details">
                    <h3>Weather Radar Snow and Storm Cell Detection</h3>
                    <p><em>Personal Project</em></p>
                    <p>
                        <a href="https://github.com/RyangDiaz/WRSCT" target="_blank">[Code]</a>
                    </p>
                    <p>We use classical computer vision tecchniques to segment snow and storm cells from weather radar images.</p>
                </div>
            </div>
        </section>

    </div>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const projectsSection = document.getElementById('projects-section');
            const toggleButton = document.getElementById('toggle-more-projects');

            if (!projectsSection || !toggleButton) {
                if (toggleButton) toggleButton.style.display = 'none'; // Hide button if section not found
                return;
            }

            const allProjects = Array.from(projectsSection.querySelectorAll('.project-entry'));
            const showProjects = allProjects.filter(p => p.classList.contains('show'));
            const hideProjectsInitial = allProjects.filter(p => p.classList.contains('hide'));

            // Create a wrapper for hideable projects
            const hiddenProjectsWrapper = document.createElement('div');
            hiddenProjectsWrapper.id = 'hidden-projects-wrapper';
            // This wrapper will be styled by CSS for expand/collapse effect

            // Detach existing elements that will be reordered
            showProjects.forEach(p => p.remove());
            hideProjectsInitial.forEach(p => p.remove()); // These will go into the wrapper
            toggleButton.remove();

            // Append "show" projects first
            showProjects.forEach(project => projectsSection.appendChild(project));

            // Append the toggle button if there are projects to hide
            if (hideProjectsInitial.length > 0) {
                projectsSection.appendChild(toggleButton);
            } else {
                toggleButton.style.display = 'none'; // Hide button if no 'hide' projects
            }
            
            // Populate and append the wrapper for "hide" projects
            hideProjectsInitial.forEach(project => hiddenProjectsWrapper.appendChild(project));
            if (hideProjectsInitial.length > 0) {
                projectsSection.appendChild(hiddenProjectsWrapper);
            }

            // Event listener for the toggle button
            if (hideProjectsInitial.length > 0) {
                toggleButton.addEventListener('click', function() {
                    const isOpening = !hiddenProjectsWrapper.classList.contains('expanded');
                    hiddenProjectsWrapper.classList.toggle('expanded');

                    if (isOpening) {
                        setTimeout(() => {
                            const buttonRect = toggleButton.getBoundingClientRect();
                            const bodyRect = document.body.getBoundingClientRect();
                            const viewportHeight = window.innerHeight;
                            const documentHeight = document.documentElement.scrollHeight;
                            
                            let targetScrollY = buttonRect.top - bodyRect.top - 10;
                            const maxScrollY = documentHeight - viewportHeight;
                            const finalScrollY = Math.min(targetScrollY, maxScrollY);

                            window.scrollTo({
                                top: finalScrollY,
                                behavior: 'smooth'
                            });
                        }, 50); 
                        
                        toggleButton.textContent = 'Less Projects ▲';
                    } else {
                        toggleButton.textContent = 'More Projects ▼';
                    }
                });
            }
        });
    </script>
    <script>
        // Theme toggle script
        document.addEventListener('DOMContentLoaded', function() {
            const themeToggleButton = document.getElementById('theme-toggle');
            const currentTheme = localStorage.getItem('theme');

            if (currentTheme === 'dark') {
                document.body.classList.add('dark-mode');
                themeToggleButton.textContent = '🌙';
            } else {
                themeToggleButton.textContent = '☀️';
            }

            themeToggleButton.addEventListener('click', function() {
                document.body.classList.toggle('dark-mode');
                let theme = 'light';
                if (document.body.classList.contains('dark-mode')) {
                    theme = 'dark';
                    themeToggleButton.textContent = '🌙';
                } else {
                    themeToggleButton.textContent = '☀️';
                }
                localStorage.setItem('theme', theme);
            });
        });
    </script>
</body>
</html> 